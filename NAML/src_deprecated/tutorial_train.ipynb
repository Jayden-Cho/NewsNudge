{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import datetime\n",
    "from evaluate import evaluate\n",
    "from config import model_name\n",
    "from dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = getattr(importlib.import_module(f\"model.{model_name}\"), model_name)\n",
    "config = getattr(importlib.import_module('config'), f\"{model_name}Config\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_word_embedding = torch.from_numpy(\n",
    "            np.load('../data/train/pretrained_word_embedding.npy')).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config, pretrained_word_embedding).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.NAML.news_encoder import NewsEncoder\n",
    "from model.NAML.user_encoder import UserEncoder\n",
    "from model.general.click_predictor.dot_product import DotProductClickPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.NAMLConfig"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAML(torch.nn.Module):\n",
    "    def __init__(self, config, pretrained_word_embedding=None):\n",
    "        super(NAML, self).__init__()\n",
    "        self.config = config\n",
    "        self.news_encoder = NewsEncoder(config, pretrained_word_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NewsEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_encoder = NewsEncoder(config, pretrained_word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsEncoder(torch.nn.Module):\n",
    "    def __init__(self, config, pretrained_word_embedding):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = nn.Embedding(config.num_words, config.word_embedding_dim, padding_idx=0)\n",
    "word_embedding = nn.Embedding.from_pretrained(pretrained_word_embedding, freeze=False, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoders_candidates = ['title', 'abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dropout_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoders = nn.ModuleDict({\n",
    "    name:\n",
    "    TextEncoder(word_embedding, # 위에서 만든거\n",
    "                config.word_embedding_dim, # 300\n",
    "                config.num_filters, # 300\n",
    "                config.window_size, # 3\n",
    "                config.query_vector_dim, # 200\n",
    "                config.dropout_probability # 0.2\n",
    "                )\n",
    "\n",
    "    for name in (set(config.dataset_attributes['news']) \n",
    "                & set(text_encoders_candidates))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.general.attention.additive import AdditiveAttention\n",
    "\n",
    "class TextEncoder(torch.nn.Module):\n",
    "    def __init__(self, word_embedding, word_embedding_dim, num_filters,\n",
    "                 window_size, query_vector_dim, dropout_probability):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.word_embedding = word_embedding\n",
    "        self.dropout_probability = dropout_probability\n",
    "        self.CNN = nn.Conv2d(1,\n",
    "                             num_filters, (window_size, word_embedding_dim),\n",
    "                             padding=(int((window_size - 1) / 2), 0))\n",
    "        self.additive_attention = AdditiveAttention(query_vector_dim,\n",
    "                                                    num_filters)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # batch_size, num_words_text, word_embedding_dim\n",
    "        text_vector = F.dropout(self.word_embedding(text),\n",
    "                                p=self.dropout_probability,\n",
    "                                training=self.training)\n",
    "        # batch_size, num_filters, num_words_title\n",
    "        convoluted_text_vector = self.CNN(\n",
    "            text_vector.unsqueeze(dim=1)).squeeze(dim=3)\n",
    "        # batch_size, num_filters, num_words_title\n",
    "        activated_text_vector = F.dropout(F.relu(convoluted_text_vector),\n",
    "                                          p=self.dropout_probability,\n",
    "                                          training=self.training)\n",
    "\n",
    "        # batch_size, num_filters\n",
    "        text_vector = self.additive_attention(\n",
    "            activated_text_vector.transpose(1, 2))\n",
    "        return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoders = nn.ModuleDict({\n",
    "            name:\n",
    "            TextEncoder(word_embedding, config.word_embedding_dim,\n",
    "                        config.num_filters, config.window_size,\n",
    "                        config.query_vector_dim, config.dropout_probability)\n",
    "            for name in (set(config.dataset_attributes['news'])\n",
    "                         & set(text_encoders_candidates))\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = candidate_news[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors = [\n",
    "    encoder(news[name].to(device))\n",
    "    for name, encoder in text_encoders.items()\n",
    "]\n",
    "\n",
    "element_vectors = [\n",
    "    encoder(news[name].to(device))\n",
    "    for name, encoder in element_encoders.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = text_vectors + [element_vectors[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_attention = AdditiveAttention(config.query_vector_dim,\n",
    "                                            config.num_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_news_vector = final_attention(\n",
    "    torch.stack(all_vectors, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 300])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_news_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElementEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElementEncoder(torch.nn.Module):\n",
    "    def __init__(self, embedding, linear_input_dim, linear_output_dim):\n",
    "        super(ElementEncoder, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.linear = nn.Linear(linear_input_dim, linear_output_dim)\n",
    "\n",
    "    def forward(self, element):\n",
    "        return F.relu(self.linear(self.embedding(element)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_encoders_candidates = ['category', 'subcategory']\n",
    "element_encoders = nn.ModuleDict({\n",
    "    name:\n",
    "    ElementEncoder(category_embedding, config.category_embedding_dim,\n",
    "                    config.num_filters)\n",
    "    for name in (set(config.dataset_attributes['news'])\n",
    "                    & set(element_encoders_candidates))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAML(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (text_encoders): ModuleDict(\n",
      "      (abstract): TextEncoder(\n",
      "        (word_embedding): Embedding(70975, 300, padding_idx=0)\n",
      "        (CNN): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
      "        (additive_attention): AdditiveAttention(\n",
      "          (linear): Linear(in_features=300, out_features=200, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (title): TextEncoder(\n",
      "        (word_embedding): Embedding(70975, 300, padding_idx=0)\n",
      "        (CNN): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
      "        (additive_attention): AdditiveAttention(\n",
      "          (linear): Linear(in_features=300, out_features=200, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (element_encoders): ModuleDict(\n",
      "      (category): ElementEncoder(\n",
      "        (embedding): Embedding(275, 100, padding_idx=0)\n",
      "        (linear): Linear(in_features=100, out_features=300, bias=True)\n",
      "      )\n",
      "      (subcategory): ElementEncoder(\n",
      "        (embedding): Embedding(275, 100, padding_idx=0)\n",
      "        (linear): Linear(in_features=100, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (final_attention): AdditiveAttention(\n",
      "      (linear): Linear(in_features=300, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (user_encoder): UserEncoder(\n",
      "    (additive_attention): AdditiveAttention(\n",
      "      (linear): Linear(in_features=300, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (click_predictor): DotProductClickPredictor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if model_name != 'Exp1':\n",
    "    print(model)\n",
    "else:\n",
    "    print(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset('../data/train/behaviors_parsed.tsv',\n",
    "                        '../data/train/news_parsed.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = iter(\n",
    "    DataLoader(dataset,\n",
    "               batch_size=config.batch_size,\n",
    "               shuffle=True,\n",
    "               num_workers=config.num_workers,\n",
    "               drop_last=True,\n",
    "               pin_memory=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizers = [torch.optim.Adam(model.parameters(), lr=config.learning_rate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "loss_full = []\n",
    "exhaustion_count = 0\n",
    "step = 0\n",
    "#early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = next(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(minibatch[\"candidate_news\"], minibatch[\"clicked_news\"])\n",
    "y = torch.zeros(len(y_pred)).long().to(device)\n",
    "loss = criterion(y_pred, y)\n",
    "\n",
    "loss_full.append(loss.item())\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_news = minibatch[\"candidate_news\"]\n",
    "clicked_news = minibatch[\"clicked_news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_news_vector = torch.stack(\n",
    "    [news_encoder(x) for x in candidate_news], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_news_vector = torch.stack(\n",
    "    [news_encoder(x) for x in clicked_news], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vector = final_attention(clicked_news_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 300])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_news_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 300])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_predictor = DotProductClickPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.9181, 10.3862, 12.7622],\n",
       "        [10.1982, 11.1527, 11.3974],\n",
       "        [ 9.6340,  9.9506,  9.5034],\n",
       "        [12.4641, 13.4475, 13.3934],\n",
       "        [ 9.8207,  8.7124,  9.1460],\n",
       "        [11.2624, 11.1223, 10.4270],\n",
       "        [ 7.8568, 11.3698,  9.9877],\n",
       "        [ 9.5206, 12.4250, 11.4712],\n",
       "        [12.4032, 11.8798, 12.1187],\n",
       "        [ 9.5549, 12.2385, 11.8226],\n",
       "        [10.1315,  8.4419, 10.5272],\n",
       "        [ 9.0040, 10.6466,  8.2396],\n",
       "        [ 8.0947,  9.7876,  9.1364],\n",
       "        [12.4731, 11.5728, 12.8593],\n",
       "        [12.3729, 14.5744, 13.6423],\n",
       "        [11.8174, 13.3805, 10.9955]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_predictor(candidate_news_vector, user_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer in optimizers:\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_batches_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': tensor([ 9,  9,  1, 13,  1,  1, 17, 40, 40, 11, 40, 81,  3,  1, 13, 33,  3, 40,\n",
       "         59,  1,  3, 81, 40,  9,  1,  3,  5,  9,  5, 31,  3, 17,  5,  5,  9, 13,\n",
       "          9,  5,  5, 33,  9,  1, 40, 40, 33, 31, 81, 59,  1, 40,  5,  5, 31,  3,\n",
       "          5,  5,  3,  5, 40, 45, 13, 81,  5,  5, 59,  9, 17,  5,  9, 40, 81,  5,\n",
       "          1, 31,  5,  9,  5,  1,  1,  5,  5, 33, 40,  5,  3,  3,  5,  5,  5, 40,\n",
       "         40,  5,  5, 17,  5,  1, 81,  3, 22, 17,  1,  9,  5, 40, 59, 81, 17,  9,\n",
       "          5,  9,  5,  5, 40,  5,  5, 13, 59, 31,  5, 22, 11,  9,  9, 40,  5,  1,\n",
       "          3, 40]),\n",
       " 'subcategory': tensor([200,  10,   2, 108,  36,   2,  27,  41,  41,  12,  64,  82,  16,   7,\n",
       "          21,  43,  16,  94, 103,  36,  70, 235,  64,  10,   2,  20,   6,  10,\n",
       "         101,  47,  20,  71,  68,   6,  10, 108, 200,  68, 101,  43,  75, 155,\n",
       "         176,  41,  43,  32, 125,  89, 100,  94,  25,  68, 109,  20,  74,  68,\n",
       "          70,  68,  64,  97, 108, 125,  68,  74,  89,  49,  27,  68,  39,  64,\n",
       "         125,   6,  36, 109,  68,  75, 101,  56,  91,  25,  68,  34,  64,  68,\n",
       "          16,  78, 101, 175, 101,  64,  64,  68, 101, 117, 101,   7,  82,  20,\n",
       "         259,  27,  36,  10, 101,  64, 128,  82,  27,  10, 101,  10, 175,  68,\n",
       "          90, 175, 101, 196,  89,  32,  68,  23,  12,  10,  35,  64,  25,   2,\n",
       "          16,  90]),\n",
       " 'title': tensor([[ 5413, 11266,   210,  ...,     0,     0,     0],\n",
       "         [ 5057,   541,  2552,  ...,     0,     0,     0],\n",
       "         [   56, 65419,   924,  ...,     5,   194,   842],\n",
       "         ...,\n",
       "         [   56, 65419,   924,  ...,     5,   194,   842],\n",
       "         [  984,  5884,    34,  ...,     0,     0,     0],\n",
       "         [20732,   605,  2398,  ...,     0,     0,     0]]),\n",
       " 'abstract': tensor([[1433,    1, 8298,  ...,    0,    0,    0],\n",
       "         [1814,  379, 3203,  ..., 4972, 4037,   47],\n",
       "         [ 237,  194, 1829,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 237,  194, 1829,  ...,    0,    0,    0],\n",
       "         [  34,  284, 1437,  ...,    0,    0,    0],\n",
       "         [ 689,  837,   42,  ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch[\"candidate_news\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
